name: Python Test

on: [push, pull_request]

jobs:
  build-and-test:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Cache data directory
      uses: actions/cache@v3
      with:
        path: ./data
        key: data-${{ github.run_id }}
        restore-keys: |
          data-

    - name: Build and cache Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: false
        load: true
        tags: "my-image:latest"
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Check data folder size
      id: check_folder
      run: |
        if [[ ! -d ./data || $(du -sb ./data | awk '{print $1/1024/1024/1024}') < 2 ]]; then
            echo "Download required, data folder does not exist or is 2 GB in size."
            echo "data_download_required=true" >> $GITHUB_ENV
        else
            echo "No download required, data folder is less than 2 GB in size."
            echo "data_download_required=false" >> $GITHUB_ENV
        fi

    # Download data from if the data folder is less than 2 GB
    - name: Download data
      if: env.data_download_required == 'true'
      run: curl -L -o ModelNet10-SO3.zip ${{ secrets.DOWNLOAD_URL }}

    # Add this step after the data download step
    #- name: List data directory contents (after download)
    #  run: ls -alh && ls -alh ./data

    - name: List images
      run: docker images

    - name: Run tests
      run: |
        docker run --ipc=host -v ${{ github.workspace }}:/workspace my-image:latest /bin/bash -c "\
          pip install -r requirements.txt torch-tb-profiler pytest && \
          ls -alh /workspace/data && \
          ls -alh /workspace/data/ModelNet10-SO3 && \
          /bin/bash download_modelnet10-SO3-dataset.sh && \
          python -m unittest discover -p test_training.py"
